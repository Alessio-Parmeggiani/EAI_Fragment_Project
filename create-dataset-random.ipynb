{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print grid in readable format\n",
    "def pretty_print(grid):\n",
    "    for row in grid:\n",
    "        print(row)\n",
    "\n",
    "#from path of description file get the coupling grid, model data and \n",
    "#remove models with error\n",
    "def process_file(path):\n",
    "    with open(path,'r') as f:\n",
    "        #don't consider first two lines\n",
    "        f.readline()           #segmenti x x x\n",
    "        f.readline()           #rotazioni x x x\n",
    "\n",
    "        line=f.readline()      #numero pezzi x  \n",
    "\n",
    "        #get number of fragments\n",
    "        number=int(re.findall(\"\\d+\",line)[0])\n",
    "\n",
    "        #coupling matrix\n",
    "        grid=[]\n",
    "        for i in range(number):\n",
    "            line=f.readline()\n",
    "            ret=re.findall('-1|0|1',line)\n",
    "            grid.append(list(map(int,ret)))\n",
    "\n",
    "        #model data\n",
    "        model_names=[]\n",
    "        non_valid_indeces=[]\n",
    "        for m in range(number):\n",
    "            f.readline()        #blank line\n",
    "            name=f.readline()   #model name\n",
    "            mesh=f.readline()   #mesh n\n",
    "            f.readline()        #external n\n",
    "            f.readline()        #internal n\n",
    "\n",
    "            #if mesh=0 I don't consider the element\n",
    "            mesh_n=int(mesh.rstrip().split(\" \")[1]) \n",
    "            if mesh_n!=0: \n",
    "                #try create file name\n",
    "                file_name= name.rstrip().replace(\".\",\"_\")\n",
    "                model_names.append(file_name)          \n",
    "            else:\n",
    "                #saving indices to remove later\n",
    "                non_valid_indeces.append(m)\n",
    "\n",
    "        #removing elements from grid\n",
    "        #sorted in reverse to avoid wrong index\n",
    "        for index in sorted(non_valid_indeces, reverse=True):\n",
    "            #remove row\n",
    "            del grid[index]\n",
    "            #remove columns\n",
    "            for row in grid:\n",
    "                del row[index]\n",
    "        \n",
    "        return grid,model_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a set of fragments (i.e. a subfolder)\n",
    "def get_set(folder,verbose=True):\n",
    "    folder_path=os.path.join(main_path,folder)\n",
    "    models_file=[]\n",
    "\n",
    "    #files are either text files or models\n",
    "    for file in os.listdir(folder_path):\n",
    "        if '.txt' in file:\n",
    "            description_file=file\n",
    "        elif '.stl' in file:\n",
    "            #not used, they are not in the same order of the file\n",
    "            models_file.append(file)\n",
    "\n",
    "    #parsing description file\n",
    "    full_description_file=os.path.join(folder_path,description_file)\n",
    "    grid,model_names=process_file(full_description_file)\n",
    "\n",
    "    #get path of models of current set\n",
    "    model_prefix=folder.replace(\"generatedTest_\",\"\")\n",
    "    complete_models_path=[]\n",
    "    for i in range(len(model_names)):\n",
    "        #e.g. 2021_11_29_10_00_40_Cube_001.stl\n",
    "        correct_model_name=f\"{model_prefix}_{model_names[i]}.stl\"\n",
    "        #saving only names, could be useful but now not used\n",
    "        model_names[i]=correct_model_name\n",
    "\n",
    "        complete_models_path.append(os.path.join(folder_path,correct_model_name))\n",
    "\n",
    "    #create set and put into list of sets\n",
    "    set={\"models\":complete_models_path,\"grid\":grid}\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"A set: \\n\")\n",
    "        print(\"Models: \",set[\"models\"])\n",
    "        print(\"Grid: \")\n",
    "        pretty_print(set[\"grid\"])\n",
    "\n",
    "    return set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "#Create all the possible pairs of fragments\n",
    "#duplicates are not considered, e.g.: (i,j) - (j,i)\n",
    "def create_pairs(num):\n",
    "    lista = []\n",
    "    for i in range(num):\n",
    "        for j in range(i+1, num):\n",
    "            lista.append((i, j))\n",
    "\n",
    "    return lista\n",
    "\n",
    "print(create_pairs(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dataset_pairs(main_path,max_elements=-1,alpha=1):\n",
    "    num_total_pairs=0\n",
    "    num_models=0\n",
    "    num_fragments=0\n",
    "    pairs_at_folder=[]  # save number of total pairs at the end of each folder, needed to split in train-test\n",
    "    #get total number of pairs we consider:\n",
    "    \n",
    "    for folder in os.listdir(main_path):\n",
    "        #check only folders, not files\n",
    "        if '.' not in folder:\n",
    "            fragment_set=get_set(folder,verbose=False)  #set of fragments of one model\n",
    "            num_models+=1\n",
    "            num_fragments+=len(fragment_set[\"models\"])\n",
    "            #get total number of adjacent pairs of fragments\n",
    "            #i.e. number of 1 in the grid\n",
    "            grid = np.array(fragment_set[\"grid\"])\n",
    "            unique, counts = np.unique(grid, return_counts=True)\n",
    "            dic = dict(zip(unique, counts))\n",
    "            #divide by two because we consider half of the pairs, not both of (i,j),(j,i)\n",
    "            num_zeros = int(dic[0]/2)\n",
    "            num_ones = int(dic[1]/2)\n",
    "\n",
    "            #consider only alpha*N not adjacent pairs\n",
    "            max_not_adjacent_pairs=alpha*num_ones\n",
    "            estimated_num_pairs=int(min(max_not_adjacent_pairs,num_zeros)+num_ones)\n",
    "            num_total_pairs+=estimated_num_pairs\n",
    "            pairs_at_folder.append(num_total_pairs)\n",
    "\n",
    "    if max_elements>0:\n",
    "        num_total_pairs=min(max_elements,num_total_pairs)\n",
    "    print(\"dataset will contain:\", num_total_pairs,\" total pairs\")\n",
    "    print(\"dataset has \",num_models,\" models and \",num_fragments,\" fragments\")\n",
    "    return num_total_pairs,pairs_at_folder\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the mesh sample the pointcloud and translate to center\n",
    "def get_pointcloud(mesh,num_points):\n",
    "    pointcloud=mesh.sample_points_poisson_disk(num_points)\n",
    "\n",
    "    center=pointcloud.get_center()\n",
    "    pointcloud=pointcloud.translate(center*-1)\n",
    "\n",
    "    return pointcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative approach to getting normals, not used\n",
    "#for each point of the point cloud get the normals of the nearest vertices in the original mesh\n",
    "def get_nearest_normal(point,mesh):\n",
    "    min_index=None\n",
    "    min_dist=float(\"inf\")\n",
    "    for i in range(len(mesh.vertices)):\n",
    "        v=mesh.vertices[i]\n",
    "        squared_dist = np.sum((point-v)**2, axis=0)\n",
    "        dist = np.sqrt(squared_dist)\n",
    "        if dist<min_dist:\n",
    "            min_dist=dist\n",
    "            min_index=i\n",
    "    return mesh.vertex_normals[i]\n",
    "\n",
    "def get_nearest_normals(pointcloud,mesh):\n",
    "    normals=[]\n",
    "    for p in pointcloud.points:\n",
    "        normals.append(get_nearest_normal(p,mesh))\n",
    "    return normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(main_path,num_points,max_elements=-1,alpha=1):\n",
    "    \n",
    "    num_elements=0\n",
    "    num_pairs=0             # number of pairs we put in dataset (train+test)\n",
    "    num_train_pairs=0       # number of pairs in train\n",
    "    num_test_pairs=0        # number of pairs in test\n",
    "    num_val_pairs=0\n",
    "    num_total_pairs=0       # total number of pairs, including those we don't put in dataset (~1.5 Millions with the smaller dataset)\n",
    "    folder_index = 0\n",
    "    tot_num_adjacent=0\n",
    "\n",
    "    sets=[]\n",
    "\n",
    "    \n",
    "    prob_test=0.15\n",
    "    prob_val=0.15\n",
    "    prob_train=1-prob_test-prob_val\n",
    "\n",
    "    print(\"Creating dataset...\")\n",
    "\n",
    "    dataset_total_pairs,pairs_at_folder=count_dataset_pairs(main_path,max_elements,alpha)\n",
    "\n",
    "    dataset_file=None\n",
    "    dataset_file_name=f\"dataset_{dataset_total_pairs}pairs_{num_points}points_center_random_normals_chunk_alpha{alpha}.hdf5\"\n",
    "\n",
    "    with open(\".gitignore\",\"a\") as f:\n",
    "        f.write(f\"{dataset_file_name}\\n\")\n",
    "\n",
    "    try: \n",
    "        dataset_file.close()\n",
    "        os.remove(dataset_file_name)\n",
    "    except:\n",
    "        print(\"file dataset not found, creating\")\n",
    "\n",
    "    chunks_size=100\n",
    "    dataset_file=h5py.File(dataset_file_name, 'w')\n",
    "\n",
    "    train_total_pairs=int(dataset_total_pairs*(prob_train))\n",
    "    train_data=dataset_file.create_dataset(\"train_data\", (train_total_pairs,2,num_points,3),chunks=(chunks_size,2,num_points,3))\n",
    "    train_normals=dataset_file.create_dataset(\"train_normals\", (train_total_pairs,2,num_points,3),chunks=(chunks_size,2,num_points,3))\n",
    "    train_labels=dataset_file.create_dataset(\"train_labels\", (train_total_pairs,),dtype='i',chunks=(chunks_size,))\n",
    "    \n",
    "    test_total_pairs=int(dataset_total_pairs*prob_test)\n",
    "    test_data=dataset_file.create_dataset(\"test_data\", (test_total_pairs,2,num_points,3),chunks=(chunks_size,2,num_points,3))\n",
    "    test_normals=dataset_file.create_dataset(\"test_normals\", (test_total_pairs,2,num_points,3),chunks=(chunks_size,2,num_points,3))\n",
    "    test_labels=dataset_file.create_dataset(\"test_labels\", (test_total_pairs,),dtype='i',chunks=(chunks_size,))\n",
    "\n",
    "    val_total_pairs=int(dataset_total_pairs*prob_test)\n",
    "    val_data=dataset_file.create_dataset(\"val_data\", (val_total_pairs,2,num_points,3),chunks=(chunks_size,2,num_points,3))\n",
    "    val_normals=dataset_file.create_dataset(\"val_normals\", (val_total_pairs,2,num_points,3),chunks=(chunks_size,2,num_points,3))\n",
    "    val_labels=dataset_file.create_dataset(\"val_labels\", (val_total_pairs,),dtype='i',chunks=(chunks_size,))\n",
    "    \n",
    "\n",
    "    total_dataset_start_time=time.time()\n",
    "\n",
    "    #indexes for saving data on file\n",
    "    #start from -1 because dataset start at index 0\n",
    "    train_index=-1\n",
    "    test_index=-1\n",
    "    val_index=-1\n",
    "\n",
    "    print(f\"Each point cloud is sampled with {num_points} points\\n\\n\")\n",
    "    for folder in os.listdir(main_path):\n",
    "        #check only folders, not files\n",
    "        if '.' not in folder:\n",
    "            set_start_time=time.time()\n",
    "            print(f\"\\n\\nStarting set {folder_index}: folder - {folder}\")  \n",
    "\n",
    "            set_train_data=[]\n",
    "            set_train_labels=[]\n",
    "            set_train_normals=[]\n",
    "\n",
    "            set_test_data=[]\n",
    "            set_test_labels=[]\n",
    "            set_test_normals=[]\n",
    "\n",
    "            set_val_data=[]\n",
    "            set_val_labels=[]\n",
    "            set_val_normals=[]\n",
    "\n",
    "            #GET SET INFORMATIONS\n",
    "            fragment_set=get_set(folder,verbose=False)  #set of fragments of one model\n",
    "            num_elements+=len(fragment_set[\"models\"])\n",
    "            sets.append(fragment_set)\n",
    "            \n",
    "            #save pointcloud of meshes\n",
    "            set_pointcloud=[]\n",
    "            set_normals=[]\n",
    "\n",
    "            for path in fragment_set[\"models\"]:\n",
    "                mesh=o3d.io.read_triangle_mesh(path)\n",
    "                pointcloud=get_pointcloud(mesh,num_points)\n",
    "                #normals=get_nearest_normals(pointcloud,mesh)\n",
    "\n",
    "                set_pointcloud.append(pointcloud)\n",
    "                #set_normals.append(normals)\n",
    "                \n",
    "\n",
    "            #get indeces of pairs\n",
    "            pairs=create_pairs(len(fragment_set[\"models\"]))\n",
    "\n",
    "            #shuffle to get random pairs not in order\n",
    "            random.shuffle(pairs)\n",
    "\n",
    "            #get total number of adjacent pairs of fragments\n",
    "            #i.e. number of 1 in the grid\n",
    "            grid = np.array(fragment_set[\"grid\"])\n",
    "            unique, counts = np.unique(grid, return_counts=True)\n",
    "            dic = dict(zip(unique, counts))\n",
    "            #divide by two because we consider half of the pairs, not both of (i,j),(j,i)\n",
    "            num_zeros = int(dic[0]/2)\n",
    "            num_ones = int(dic[1]/2)\n",
    "\n",
    "            #considerare solo a*N coppie non adiacenti\n",
    "            max_not_adjacent_pairs=alpha*num_ones\n",
    "\n",
    "            estimated_num_pairs=int(min(max_not_adjacent_pairs,num_zeros)+num_ones)\n",
    "\n",
    "            print(\"Set stats: \")\n",
    "            print(f\"  --number of fragments: {len(fragment_set['models'])}\")\n",
    "            print(f\"  --total adjacent pairs: {num_ones}; total not adjacent pairs: {num_zeros}\")\n",
    "            print(f\"  --dataset for set will contain: {estimated_num_pairs} pairs\")\n",
    "            print(f\"     --> adj: {num_ones}    n-adj: {int(min(max_not_adjacent_pairs,num_zeros))}\")\n",
    "\n",
    "            #some stats\n",
    "            set_num_not_adjacent=0\n",
    "            set_num_adjacent=0\n",
    "            current_set_pairs=0\n",
    "            current_set_not_adj=0\n",
    "            \n",
    "            for pair in pairs:\n",
    "                #if limit of maximum pairs is not exceeded\n",
    "                if max_elements<0 or num_pairs<=max_elements:\n",
    "                        \n",
    "                    num_total_pairs+=1\n",
    "                    idx1,idx2=pair\n",
    "                    label=fragment_set[\"grid\"][idx1][idx2]\n",
    "                    \n",
    "                    #total number of not adjacent\n",
    "                    if label==0:\n",
    "                        set_num_not_adjacent+=1\n",
    "                    else:\n",
    "                        set_num_adjacent+=1\n",
    "                        tot_num_adjacent+=1\n",
    "                    \n",
    "                    #if adjacent pair or not adjacent pairs limit not exceeded\n",
    "                    if label==1 or (label==0 and set_num_not_adjacent<=max_not_adjacent_pairs):\n",
    "\n",
    "                        #add stats for number of fragments in dataset and current set\n",
    "                        num_pairs+=1\n",
    "                        current_set_pairs+=1\n",
    "\n",
    "                        #add stats for adjacent fragment in dataset\n",
    "                        if label==0: current_set_not_adj+=1\n",
    "\n",
    "                        pointcloud1=set_pointcloud[idx1]\n",
    "                        pointcloud2=set_pointcloud[idx2]\n",
    "\n",
    "                        #generate pair of pointclouds\n",
    "                        pointcloud_pair=[ np.asarray(pointcloud1.points) ,  np.asarray(pointcloud2.points) ]\n",
    "\n",
    "                        normals_pair=[ np.asarray(pointcloud1.normals) ,  np.asarray(pointcloud2.normals) ]\n",
    "\n",
    "                        #compute where to put this pair\n",
    "                        destination_set=np.random.choice([\"train\",\"test\",\"val\"], p=[prob_train, prob_test, prob_val])\n",
    "\n",
    "                        #check if still available space\n",
    "                        if destination_set==\"train\" and num_train_pairs>train_total_pairs:\n",
    "                            destination_set=\"test\"\n",
    "                        \n",
    "                        if destination_set==\"test\" and num_test_pairs>test_total_pairs:\n",
    "                            destination_set=\"val\"\n",
    "\n",
    "                        if destination_set==\"val\" and num_val_pairs>val_total_pairs:\n",
    "                            destination_set=\"\"\n",
    "\n",
    "                        if destination_set:\n",
    "                            if destination_set==\"train\":\n",
    "                                num_train_pairs+=1\n",
    "                                set_train_data.append(pointcloud_pair)\n",
    "                                set_train_labels.append(label)\n",
    "                                set_train_normals.append(normals_pair)\n",
    "\n",
    "                            elif destination_set==\"test\":\n",
    "                                num_test_pairs+=1\n",
    "                                set_test_data.append(pointcloud_pair)\n",
    "                                set_test_labels.append(label)\n",
    "                                set_test_normals.append(normals_pair)\n",
    "                                \n",
    "                            elif destination_set==\"val\":\n",
    "                                num_val_pairs+=1\n",
    "                                set_val_data.append(pointcloud_pair)\n",
    "                                set_val_labels.append(label)\n",
    "                                set_val_normals.append(normals_pair)\n",
    "\n",
    "\n",
    "            set_elapsed_time=time.time()-set_start_time\n",
    "            print(\"Set completed in: %.3f seconds\" % (set_elapsed_time),end=\": \")\n",
    "            print(f\"added {current_set_pairs} pairs --> adj: {set_num_adjacent}   n_adj: {current_set_not_adj}\")\n",
    "            print(f\"currently dataset contains {num_pairs} pairs\",end=\". \")\n",
    "            print()\n",
    "            \n",
    "            len_train=len(set_train_data)\n",
    "            train_data[train_index:train_index+len_train]=set_train_data\n",
    "            train_labels[train_index:train_index+len_train]=set_train_labels\n",
    "            train_normals[train_index:train_index+len_train]=set_train_normals\n",
    "            train_index+=len_train\n",
    "\n",
    "            len_test=len(set_test_data)\n",
    "            test_data[test_index:test_index+len_test]=set_test_data\n",
    "            test_labels[test_index:test_index+len_test]=set_test_labels\n",
    "            test_normals[test_index:test_index+len_test]=set_test_normals\n",
    "            test_index+=len_test\n",
    "\n",
    "            len_val=len(set_val_data)\n",
    "            val_data[val_index:val_index+len_val]=set_val_data\n",
    "            val_labels[val_index:val_index+len_val]=set_val_labels\n",
    "            val_normals[val_index:val_index+len_val]=set_val_normals\n",
    "            val_index+=len_val\n",
    "\n",
    "\n",
    "\n",
    "            folder_index+=1\n",
    "\n",
    "\n",
    "    dataset_file.close()\n",
    "    total_dataset_time=time.time()-total_dataset_start_time\n",
    "    print(f\"Dataset contains {num_elements} fragments --> {num_total_pairs} total pairs \")\n",
    "    print(\"we consider only: \",num_pairs,\" pairs, of which \", tot_num_adjacent, \"are adjacent\")\n",
    "    print(f\"Train set: {num_train_pairs},   test set: {num_test_pairs}, val set: {num_val_pairs}\")\n",
    "    print(f\"but it should be: train,test,val: {train_total_pairs},{test_total_pairs},{val_total_pairs}\")\n",
    "    print(\"total time: %.3f seconds\" % (total_dataset_time))\n",
    "    #return np.array(all_data),np.array(all_labels)\n",
    "\n",
    "\n",
    "\n",
    "#used in class ModelNet40\n",
    "#for now we don't use it\n",
    "def translate_pointcloud(pointcloud):\n",
    "    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])\n",
    "    xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])\n",
    "       \n",
    "    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')\n",
    "    return translated_pointcloud         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i save all the sets of fragments\n",
    "sets=[]\n",
    "\n",
    "#root folder\n",
    "main_path=\"produzione_29112021\"\n",
    "\n",
    "num_points=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dataset_pairs(main_path,max_elements=-1,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "dataset will contain: 179608  total pairs\n",
      "file dataset not found, creating\n",
      "Each point cloud is sampled with 100 points\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting set 0: folder - generatedTest_2021_11_29_10_00_40\n",
      "Set stats: \n",
      "  --number of fragments: 8\n",
      "  --total adjacent pairs: 19; total not adjacent pairs: 9\n",
      "  --dataset for set will contain: 28 pairs\n",
      "     --> adj: 19    n-adj: 9\n",
      "Set completed in: 1.295 seconds: added 28 pairs --> adj: 19   n_adj: 9\n",
      "currently dataset contains 28 pairs. \n",
      "\n",
      "\n",
      "Starting set 1: folder - generatedTest_2021_11_29_10_01_59\n",
      "Set stats: \n",
      "  --number of fragments: 8\n",
      "  --total adjacent pairs: 19; total not adjacent pairs: 9\n",
      "  --dataset for set will contain: 28 pairs\n",
      "     --> adj: 19    n-adj: 9\n",
      "Set completed in: 0.557 seconds: added 28 pairs --> adj: 19   n_adj: 9\n",
      "currently dataset contains 56 pairs. \n",
      "\n",
      "\n",
      "Starting set 2: folder - generatedTest_2021_11_29_10_02_12\n",
      "Set stats: \n",
      "  --number of fragments: 8\n",
      "  --total adjacent pairs: 18; total not adjacent pairs: 10\n",
      "  --dataset for set will contain: 28 pairs\n",
      "     --> adj: 18    n-adj: 10\n",
      "Set completed in: 0.614 seconds: added 28 pairs --> adj: 18   n_adj: 10\n",
      "currently dataset contains 84 pairs. \n",
      "\n",
      "\n",
      "Starting set 3: folder - generatedTest_2021_11_29_10_02_50\n",
      "Set stats: \n",
      "  --number of fragments: 27\n",
      "  --total adjacent pairs: 97; total not adjacent pairs: 254\n",
      "  --dataset for set will contain: 194 pairs\n",
      "     --> adj: 97    n-adj: 97\n",
      "Set completed in: 1.731 seconds: added 194 pairs --> adj: 97   n_adj: 97\n",
      "currently dataset contains 278 pairs. \n",
      "\n",
      "\n",
      "Starting set 4: folder - generatedTest_2021_11_29_10_02_58\n",
      "Set stats: \n",
      "  --number of fragments: 26\n",
      "  --total adjacent pairs: 86; total not adjacent pairs: 239\n",
      "  --dataset for set will contain: 172 pairs\n",
      "     --> adj: 86    n-adj: 86\n",
      "Set completed in: 2.330 seconds: added 172 pairs --> adj: 86   n_adj: 86\n",
      "currently dataset contains 450 pairs. \n",
      "\n",
      "\n",
      "Starting set 5: folder - generatedTest_2021_11_29_10_03_27\n",
      "Set stats: \n",
      "  --number of fragments: 27\n",
      "  --total adjacent pairs: 94; total not adjacent pairs: 257\n",
      "  --dataset for set will contain: 188 pairs\n",
      "     --> adj: 94    n-adj: 94\n",
      "Set completed in: 2.318 seconds: added 188 pairs --> adj: 94   n_adj: 94\n",
      "currently dataset contains 638 pairs. \n",
      "\n",
      "\n",
      "Starting set 6: folder - generatedTest_2021_11_29_10_03_51\n",
      "Set stats: \n",
      "  --number of fragments: 64\n",
      "  --total adjacent pairs: 276; total not adjacent pairs: 1740\n",
      "  --dataset for set will contain: 552 pairs\n",
      "     --> adj: 276    n-adj: 276\n",
      "Set completed in: 6.224 seconds: added 552 pairs --> adj: 276   n_adj: 276\n",
      "currently dataset contains 1190 pairs. \n",
      "\n",
      "\n",
      "Starting set 7: folder - generatedTest_2021_11_29_10_04_09\n",
      "Set stats: \n",
      "  --number of fragments: 57\n",
      "  --total adjacent pairs: 242; total not adjacent pairs: 1354\n",
      "  --dataset for set will contain: 484 pairs\n",
      "     --> adj: 242    n-adj: 242\n",
      "Set completed in: 4.688 seconds: added 484 pairs --> adj: 242   n_adj: 242\n",
      "currently dataset contains 1674 pairs. \n",
      "\n",
      "\n",
      "Starting set 8: folder - generatedTest_2021_11_29_10_04_25\n",
      "Set stats: \n",
      "  --number of fragments: 59\n",
      "  --total adjacent pairs: 241; total not adjacent pairs: 1470\n",
      "  --dataset for set will contain: 482 pairs\n",
      "     --> adj: 241    n-adj: 241\n",
      "Set completed in: 4.651 seconds: added 482 pairs --> adj: 241   n_adj: 241\n",
      "currently dataset contains 2156 pairs. \n",
      "\n",
      "\n",
      "Starting set 9: folder - generatedTest_2021_11_29_10_05_19\n",
      "Set stats: \n",
      "  --number of fragments: 216\n",
      "  --total adjacent pairs: 1072; total not adjacent pairs: 22148\n",
      "  --dataset for set will contain: 2144 pairs\n",
      "     --> adj: 1072    n-adj: 1072\n",
      "Set completed in: 19.757 seconds: added 2144 pairs --> adj: 1072   n_adj: 1072\n",
      "currently dataset contains 4300 pairs. \n",
      "\n",
      "\n",
      "Starting set 10: folder - generatedTest_2021_11_29_10_06_11\n",
      "Set stats: \n",
      "  --number of fragments: 187\n",
      "  --total adjacent pairs: 930; total not adjacent pairs: 16461\n",
      "  --dataset for set will contain: 1860 pairs\n",
      "     --> adj: 930    n-adj: 930\n",
      "Set completed in: 14.441 seconds: added 1860 pairs --> adj: 930   n_adj: 930\n",
      "currently dataset contains 6160 pairs. \n",
      "\n",
      "\n",
      "Starting set 11: folder - generatedTest_2021_11_29_10_07_02\n",
      "Set stats: \n",
      "  --number of fragments: 208\n",
      "  --total adjacent pairs: 1019; total not adjacent pairs: 20509\n",
      "  --dataset for set will contain: 2038 pairs\n",
      "     --> adj: 1019    n-adj: 1019\n",
      "Set completed in: 18.460 seconds: added 2038 pairs --> adj: 1019   n_adj: 1019\n",
      "currently dataset contains 8198 pairs. \n",
      "\n",
      "\n",
      "Starting set 12: folder - generatedTest_2021_11_29_10_15_14\n",
      "Set stats: \n",
      "  --number of fragments: 120\n",
      "  --total adjacent pairs: 558; total not adjacent pairs: 6582\n",
      "  --dataset for set will contain: 1116 pairs\n",
      "     --> adj: 558    n-adj: 558\n",
      "Set completed in: 10.168 seconds: added 1116 pairs --> adj: 558   n_adj: 558\n",
      "currently dataset contains 9314 pairs. \n",
      "\n",
      "\n",
      "Starting set 13: folder - generatedTest_2021_11_29_10_16_04\n",
      "Set stats: \n",
      "  --number of fragments: 115\n",
      "  --total adjacent pairs: 532; total not adjacent pairs: 6023\n",
      "  --dataset for set will contain: 1064 pairs\n",
      "     --> adj: 532    n-adj: 532\n",
      "Set completed in: 11.700 seconds: added 1064 pairs --> adj: 532   n_adj: 532\n",
      "currently dataset contains 10378 pairs. \n",
      "\n",
      "\n",
      "Starting set 14: folder - generatedTest_2021_11_29_10_16_37\n",
      "Set stats: \n",
      "  --number of fragments: 119\n",
      "  --total adjacent pairs: 554; total not adjacent pairs: 6467\n",
      "  --dataset for set will contain: 1108 pairs\n",
      "     --> adj: 554    n-adj: 554\n",
      "Set completed in: 10.710 seconds: added 1108 pairs --> adj: 554   n_adj: 554\n",
      "currently dataset contains 11486 pairs. \n",
      "\n",
      "\n",
      "Starting set 15: folder - generatedTest_2021_11_29_10_17_44\n",
      "Set stats: \n",
      "  --number of fragments: 192\n",
      "  --total adjacent pairs: 936; total not adjacent pairs: 17400\n",
      "  --dataset for set will contain: 1872 pairs\n",
      "     --> adj: 936    n-adj: 936\n",
      "Set completed in: 17.476 seconds: added 1872 pairs --> adj: 936   n_adj: 936\n",
      "currently dataset contains 13358 pairs. \n",
      "\n",
      "\n",
      "Starting set 16: folder - generatedTest_2021_11_29_10_19_23\n",
      "Set stats: \n",
      "  --number of fragments: 176\n",
      "  --total adjacent pairs: 842; total not adjacent pairs: 14558\n",
      "  --dataset for set will contain: 1684 pairs\n",
      "     --> adj: 842    n-adj: 842\n",
      "Set completed in: 9.810 seconds: added 1684 pairs --> adj: 842   n_adj: 842\n",
      "currently dataset contains 15042 pairs. \n",
      "\n",
      "\n",
      "Starting set 17: folder - generatedTest_2021_11_29_10_20_52\n",
      "Set stats: \n",
      "  --number of fragments: 167\n",
      "  --total adjacent pairs: 778; total not adjacent pairs: 13083\n",
      "  --dataset for set will contain: 1556 pairs\n",
      "     --> adj: 778    n-adj: 778\n",
      "Set completed in: 8.661 seconds: added 1556 pairs --> adj: 778   n_adj: 778\n",
      "currently dataset contains 16598 pairs. \n",
      "\n",
      "\n",
      "Starting set 18: folder - generatedTest_2021_11_29_10_21_45\n",
      "Set stats: \n",
      "  --number of fragments: 160\n",
      "  --total adjacent pairs: 761; total not adjacent pairs: 11959\n",
      "  --dataset for set will contain: 1522 pairs\n",
      "     --> adj: 761    n-adj: 761\n",
      "Set completed in: 8.937 seconds: added 1522 pairs --> adj: 761   n_adj: 761\n",
      "currently dataset contains 18120 pairs. \n",
      "\n",
      "\n",
      "Starting set 19: folder - generatedTest_2021_11_29_10_22_52\n",
      "Set stats: \n",
      "  --number of fragments: 138\n",
      "  --total adjacent pairs: 605; total not adjacent pairs: 8848\n",
      "  --dataset for set will contain: 1210 pairs\n",
      "     --> adj: 605    n-adj: 605\n",
      "Set completed in: 8.164 seconds: added 1210 pairs --> adj: 605   n_adj: 605\n",
      "currently dataset contains 19330 pairs. \n",
      "\n",
      "\n",
      "Starting set 20: folder - generatedTest_2021_11_29_10_23_50\n",
      "Set stats: \n",
      "  --number of fragments: 146\n",
      "  --total adjacent pairs: 684; total not adjacent pairs: 9901\n",
      "  --dataset for set will contain: 1368 pairs\n",
      "     --> adj: 684    n-adj: 684\n",
      "Set completed in: 7.142 seconds: added 1368 pairs --> adj: 684   n_adj: 684\n",
      "currently dataset contains 20698 pairs. \n",
      "\n",
      "\n",
      "Starting set 21: folder - generatedTest_2021_11_29_10_24_57\n",
      "Set stats: \n",
      "  --number of fragments: 216\n",
      "  --total adjacent pairs: 1068; total not adjacent pairs: 22152\n",
      "  --dataset for set will contain: 2136 pairs\n",
      "     --> adj: 1068    n-adj: 1068\n",
      "Set completed in: 13.345 seconds: added 2136 pairs --> adj: 1068   n_adj: 1068\n",
      "currently dataset contains 22834 pairs. \n",
      "\n",
      "\n",
      "Starting set 22: folder - generatedTest_2021_11_29_10_26_01\n",
      "Set stats: \n",
      "  --number of fragments: 180\n",
      "  --total adjacent pairs: 856; total not adjacent pairs: 15254\n",
      "  --dataset for set will contain: 1712 pairs\n",
      "     --> adj: 856    n-adj: 856\n",
      "Set completed in: 11.441 seconds: added 1712 pairs --> adj: 856   n_adj: 856\n",
      "currently dataset contains 24546 pairs. \n",
      "\n",
      "\n",
      "Starting set 23: folder - generatedTest_2021_11_29_10_26_56\n",
      "Set stats: \n",
      "  --number of fragments: 210\n",
      "  --total adjacent pairs: 997; total not adjacent pairs: 20948\n",
      "  --dataset for set will contain: 1994 pairs\n",
      "     --> adj: 997    n-adj: 997\n",
      "Set completed in: 11.722 seconds: added 1994 pairs --> adj: 997   n_adj: 997\n",
      "currently dataset contains 26540 pairs. \n",
      "\n",
      "\n",
      "Starting set 24: folder - generatedTest_2021_11_29_10_27_56\n",
      "Set stats: \n",
      "  --number of fragments: 84\n",
      "  --total adjacent pairs: 360; total not adjacent pairs: 3126\n",
      "  --dataset for set will contain: 720 pairs\n",
      "     --> adj: 360    n-adj: 360\n",
      "Set completed in: 4.890 seconds: added 720 pairs --> adj: 360   n_adj: 360\n",
      "currently dataset contains 27260 pairs. \n",
      "\n",
      "\n",
      "Starting set 25: folder - generatedTest_2021_11_29_10_28_22\n",
      "Set stats: \n",
      "  --number of fragments: 83\n",
      "  --total adjacent pairs: 350; total not adjacent pairs: 3053\n",
      "  --dataset for set will contain: 700 pairs\n",
      "     --> adj: 350    n-adj: 350\n",
      "Set completed in: 5.748 seconds: added 700 pairs --> adj: 350   n_adj: 350\n",
      "currently dataset contains 27960 pairs. \n",
      "\n",
      "\n",
      "Starting set 26: folder - generatedTest_2021_11_29_10_28_46\n",
      "Set stats: \n",
      "  --number of fragments: 83\n",
      "  --total adjacent pairs: 343; total not adjacent pairs: 3060\n",
      "  --dataset for set will contain: 686 pairs\n",
      "     --> adj: 343    n-adj: 343\n",
      "Set completed in: 5.510 seconds: added 686 pairs --> adj: 343   n_adj: 343\n",
      "currently dataset contains 28646 pairs. \n",
      "\n",
      "\n",
      "Starting set 27: folder - generatedTest_2021_11_29_10_29_28\n",
      "Set stats: \n",
      "  --number of fragments: 105\n",
      "  --total adjacent pairs: 470; total not adjacent pairs: 4990\n",
      "  --dataset for set will contain: 940 pairs\n",
      "     --> adj: 470    n-adj: 470\n",
      "Set completed in: 8.116 seconds: added 940 pairs --> adj: 470   n_adj: 470\n",
      "currently dataset contains 29586 pairs. \n",
      "\n",
      "\n",
      "Starting set 28: folder - generatedTest_2021_11_29_10_31_27\n",
      "Set stats: \n",
      "  --number of fragments: 99\n",
      "  --total adjacent pairs: 427; total not adjacent pairs: 4424\n",
      "  --dataset for set will contain: 854 pairs\n",
      "     --> adj: 427    n-adj: 427\n",
      "Set completed in: 6.410 seconds: added 854 pairs --> adj: 427   n_adj: 427\n",
      "currently dataset contains 30440 pairs. \n",
      "\n",
      "\n",
      "Starting set 29: folder - generatedTest_2021_11_29_10_32_18\n",
      "Set stats: \n",
      "  --number of fragments: 103\n",
      "  --total adjacent pairs: 457; total not adjacent pairs: 4796\n",
      "  --dataset for set will contain: 914 pairs\n",
      "     --> adj: 457    n-adj: 457\n",
      "Set completed in: 6.451 seconds: added 914 pairs --> adj: 457   n_adj: 457\n",
      "currently dataset contains 31354 pairs. \n",
      "\n",
      "\n",
      "Starting set 30: folder - generatedTest_2021_11_29_10_36_43\n",
      "Set stats: \n",
      "  --number of fragments: 729\n",
      "  --total adjacent pairs: 3951; total not adjacent pairs: 261405\n",
      "  --dataset for set will contain: 7902 pairs\n",
      "     --> adj: 3951    n-adj: 3951\n",
      "Set completed in: 46.118 seconds: added 7902 pairs --> adj: 3951   n_adj: 3951\n",
      "currently dataset contains 39256 pairs. \n",
      "\n",
      "\n",
      "Starting set 31: folder - generatedTest_2021_11_29_10_41_22\n",
      "Set stats: \n",
      "  --number of fragments: 695\n",
      "  --total adjacent pairs: 3662; total not adjacent pairs: 237503\n",
      "  --dataset for set will contain: 7324 pairs\n",
      "     --> adj: 3662    n-adj: 3662\n",
      "Set completed in: 43.749 seconds: added 7324 pairs --> adj: 3662   n_adj: 3662\n",
      "currently dataset contains 46580 pairs. \n",
      "\n",
      "\n",
      "Starting set 32: folder - generatedTest_2021_11_29_10_45_42\n",
      "Set stats: \n",
      "  --number of fragments: 645\n",
      "  --total adjacent pairs: 3374; total not adjacent pairs: 204316\n",
      "  --dataset for set will contain: 6748 pairs\n",
      "     --> adj: 3374    n-adj: 3374\n",
      "Set completed in: 39.735 seconds: added 6748 pairs --> adj: 3374   n_adj: 3374\n",
      "currently dataset contains 53328 pairs. \n",
      "\n",
      "\n",
      "Starting set 33: folder - generatedTest_2021_11_29_10_48_20\n",
      "Set stats: \n",
      "  --number of fragments: 343\n",
      "  --total adjacent pairs: 1801; total not adjacent pairs: 56852\n",
      "  --dataset for set will contain: 3602 pairs\n",
      "     --> adj: 1801    n-adj: 1801\n",
      "Set completed in: 24.285 seconds: added 3602 pairs --> adj: 1801   n_adj: 1801\n",
      "currently dataset contains 56930 pairs. \n",
      "\n",
      "\n",
      "Starting set 34: folder - generatedTest_2021_11_29_10_51_20\n",
      "Set stats: \n",
      "  --number of fragments: 305\n",
      "  --total adjacent pairs: 1546; total not adjacent pairs: 44814\n",
      "  --dataset for set will contain: 3092 pairs\n",
      "     --> adj: 1546    n-adj: 1546\n",
      "Set completed in: 24.464 seconds: added 3092 pairs --> adj: 1546   n_adj: 1546\n",
      "currently dataset contains 60022 pairs. \n",
      "\n",
      "\n",
      "Starting set 35: folder - generatedTest_2021_11_29_10_53_31\n",
      "Set stats: \n",
      "  --number of fragments: 314\n",
      "  --total adjacent pairs: 1587; total not adjacent pairs: 47554\n",
      "  --dataset for set will contain: 3174 pairs\n",
      "     --> adj: 1587    n-adj: 1587\n",
      "Set completed in: 24.655 seconds: added 3174 pairs --> adj: 1587   n_adj: 1587\n",
      "currently dataset contains 63196 pairs. \n",
      "\n",
      "\n",
      "Starting set 36: folder - generatedTest_2021_11_29_10_54_15\n",
      "Set stats: \n",
      "  --number of fragments: 140\n",
      "  --total adjacent pairs: 666; total not adjacent pairs: 9064\n",
      "  --dataset for set will contain: 1332 pairs\n",
      "     --> adj: 666    n-adj: 666\n",
      "Set completed in: 9.815 seconds: added 1332 pairs --> adj: 666   n_adj: 666\n",
      "currently dataset contains 64528 pairs. \n",
      "\n",
      "\n",
      "Starting set 37: folder - generatedTest_2021_11_29_10_55_01\n",
      "Set stats: \n",
      "  --number of fragments: 135\n",
      "  --total adjacent pairs: 626; total not adjacent pairs: 8419\n",
      "  --dataset for set will contain: 1252 pairs\n",
      "     --> adj: 626    n-adj: 626\n",
      "Set completed in: 8.790 seconds: added 1252 pairs --> adj: 626   n_adj: 626\n",
      "currently dataset contains 65780 pairs. \n",
      "\n",
      "\n",
      "Starting set 38: folder - generatedTest_2021_11_29_10_55_44\n",
      "Set stats: \n",
      "  --number of fragments: 128\n",
      "  --total adjacent pairs: 602; total not adjacent pairs: 7526\n",
      "  --dataset for set will contain: 1204 pairs\n",
      "     --> adj: 602    n-adj: 602\n",
      "Set completed in: 7.782 seconds: added 1204 pairs --> adj: 602   n_adj: 602\n",
      "currently dataset contains 66984 pairs. \n",
      "\n",
      "\n",
      "Starting set 39: folder - generatedTest_2021_11_29_10_57_36\n",
      "Set stats: \n",
      "  --number of fragments: 175\n",
      "  --total adjacent pairs: 854; total not adjacent pairs: 14371\n",
      "  --dataset for set will contain: 1708 pairs\n",
      "     --> adj: 854    n-adj: 854\n",
      "Set completed in: 9.466 seconds: added 1708 pairs --> adj: 854   n_adj: 854\n",
      "currently dataset contains 68692 pairs. \n",
      "\n",
      "\n",
      "Starting set 40: folder - generatedTest_2021_11_29_10_58_19\n",
      "Set stats: \n",
      "  --number of fragments: 135\n",
      "  --total adjacent pairs: 615; total not adjacent pairs: 8430\n",
      "  --dataset for set will contain: 1230 pairs\n",
      "     --> adj: 615    n-adj: 615\n",
      "Set completed in: 7.498 seconds: added 1230 pairs --> adj: 615   n_adj: 615\n",
      "currently dataset contains 69922 pairs. \n",
      "\n",
      "\n",
      "Starting set 41: folder - generatedTest_2021_11_29_10_59_06\n",
      "Set stats: \n",
      "  --number of fragments: 162\n",
      "  --total adjacent pairs: 765; total not adjacent pairs: 12276\n",
      "  --dataset for set will contain: 1530 pairs\n",
      "     --> adj: 765    n-adj: 765\n",
      "Set completed in: 9.915 seconds: added 1530 pairs --> adj: 765   n_adj: 765\n",
      "currently dataset contains 71452 pairs. \n",
      "\n",
      "\n",
      "Starting set 42: folder - generatedTest_2021_11_29_11_02_28\n",
      "Set stats: \n",
      "  --number of fragments: 504\n",
      "  --total adjacent pairs: 2695; total not adjacent pairs: 124061\n",
      "  --dataset for set will contain: 5390 pairs\n",
      "     --> adj: 2695    n-adj: 2695\n",
      "Set completed in: 29.077 seconds: added 5390 pairs --> adj: 2695   n_adj: 2695\n",
      "currently dataset contains 76842 pairs. \n",
      "\n",
      "\n",
      "Starting set 43: folder - generatedTest_2021_11_29_11_05_39\n",
      "Set stats: \n",
      "  --number of fragments: 452\n",
      "  --total adjacent pairs: 2316; total not adjacent pairs: 99610\n",
      "  --dataset for set will contain: 4632 pairs\n",
      "     --> adj: 2316    n-adj: 2316\n",
      "Set completed in: 26.845 seconds: added 4632 pairs --> adj: 2316   n_adj: 2316\n",
      "currently dataset contains 81474 pairs. \n",
      "\n",
      "\n",
      "Starting set 44: folder - generatedTest_2021_11_29_11_27_51\n",
      "Set stats: \n",
      "  --number of fragments: 472\n",
      "  --total adjacent pairs: 2426; total not adjacent pairs: 108730\n",
      "  --dataset for set will contain: 4852 pairs\n",
      "     --> adj: 2426    n-adj: 2426\n",
      "Set completed in: 27.043 seconds: added 4852 pairs --> adj: 2426   n_adj: 2426\n",
      "currently dataset contains 86326 pairs. \n",
      "\n",
      "\n",
      "Starting set 45: folder - generatedTest_2021_11_29_11_30_35\n",
      "Set stats: \n",
      "  --number of fragments: 168\n",
      "  --total adjacent pairs: 796; total not adjacent pairs: 13232\n",
      "  --dataset for set will contain: 1592 pairs\n",
      "     --> adj: 796    n-adj: 796\n",
      "Set completed in: 9.735 seconds: added 1592 pairs --> adj: 796   n_adj: 796\n",
      "currently dataset contains 87918 pairs. \n",
      "\n",
      "\n",
      "Starting set 46: folder - generatedTest_2021_11_29_11_32_07\n",
      "Set stats: \n",
      "  --number of fragments: 154\n",
      "  --total adjacent pairs: 693; total not adjacent pairs: 11088\n",
      "  --dataset for set will contain: 1386 pairs\n",
      "     --> adj: 693    n-adj: 693\n",
      "Set completed in: 8.920 seconds: added 1386 pairs --> adj: 693   n_adj: 693\n",
      "currently dataset contains 89304 pairs. \n",
      "\n",
      "\n",
      "Starting set 47: folder - generatedTest_2021_11_29_11_36_31\n",
      "Set stats: \n",
      "  --number of fragments: 163\n",
      "  --total adjacent pairs: 753; total not adjacent pairs: 12450\n",
      "  --dataset for set will contain: 1506 pairs\n",
      "     --> adj: 753    n-adj: 753\n",
      "Set completed in: 8.582 seconds: added 1506 pairs --> adj: 753   n_adj: 753\n",
      "currently dataset contains 90810 pairs. \n",
      "\n",
      "\n",
      "Starting set 48: folder - generatedTest_2022_03_04_14_00_13\n",
      "Set stats: \n",
      "  --number of fragments: 8\n",
      "  --total adjacent pairs: 19; total not adjacent pairs: 9\n",
      "  --dataset for set will contain: 28 pairs\n",
      "     --> adj: 19    n-adj: 9\n",
      "Set completed in: 0.467 seconds: added 28 pairs --> adj: 19   n_adj: 9\n",
      "currently dataset contains 90838 pairs. \n",
      "\n",
      "\n",
      "Starting set 49: folder - generatedTest_2022_03_04_14_02_07\n",
      "Set stats: \n",
      "  --number of fragments: 8\n",
      "  --total adjacent pairs: 17; total not adjacent pairs: 11\n",
      "  --dataset for set will contain: 28 pairs\n",
      "     --> adj: 17    n-adj: 11\n",
      "Set completed in: 0.376 seconds: added 28 pairs --> adj: 17   n_adj: 11\n",
      "currently dataset contains 90866 pairs. \n",
      "\n",
      "\n",
      "Starting set 50: folder - generatedTest_2022_03_04_14_02_23\n",
      "Set stats: \n",
      "  --number of fragments: 8\n",
      "  --total adjacent pairs: 19; total not adjacent pairs: 9\n",
      "  --dataset for set will contain: 28 pairs\n",
      "     --> adj: 19    n-adj: 9\n",
      "Set completed in: 0.417 seconds: added 28 pairs --> adj: 19   n_adj: 9\n",
      "currently dataset contains 90894 pairs. \n",
      "\n",
      "\n",
      "Starting set 51: folder - generatedTest_2022_03_04_14_02_53\n",
      "Set stats: \n",
      "  --number of fragments: 27\n",
      "  --total adjacent pairs: 98; total not adjacent pairs: 253\n",
      "  --dataset for set will contain: 196 pairs\n",
      "     --> adj: 98    n-adj: 98\n",
      "Set completed in: 1.307 seconds: added 196 pairs --> adj: 98   n_adj: 98\n",
      "currently dataset contains 91090 pairs. \n",
      "\n",
      "\n",
      "Starting set 52: folder - generatedTest_2022_03_04_14_03_02\n",
      "Set stats: \n",
      "  --number of fragments: 27\n",
      "  --total adjacent pairs: 98; total not adjacent pairs: 253\n",
      "  --dataset for set will contain: 196 pairs\n",
      "     --> adj: 98    n-adj: 98\n",
      "Set completed in: 1.602 seconds: added 196 pairs --> adj: 98   n_adj: 98\n",
      "currently dataset contains 91286 pairs. \n",
      "\n",
      "\n",
      "Starting set 53: folder - generatedTest_2022_03_04_14_03_12\n",
      "Set stats: \n",
      "  --number of fragments: 27\n",
      "  --total adjacent pairs: 94; total not adjacent pairs: 257\n",
      "  --dataset for set will contain: 188 pairs\n",
      "     --> adj: 94    n-adj: 94\n",
      "Set completed in: 1.186 seconds: added 188 pairs --> adj: 94   n_adj: 94\n",
      "currently dataset contains 91474 pairs. \n",
      "\n",
      "\n",
      "Starting set 54: folder - generatedTest_2022_03_04_14_04_22\n",
      "Set stats: \n",
      "  --number of fragments: 64\n",
      "  --total adjacent pairs: 274; total not adjacent pairs: 1742\n",
      "  --dataset for set will contain: 548 pairs\n",
      "     --> adj: 274    n-adj: 274\n",
      "Set completed in: 3.347 seconds: added 548 pairs --> adj: 274   n_adj: 274\n",
      "currently dataset contains 92022 pairs. \n",
      "\n",
      "\n",
      "Starting set 55: folder - generatedTest_2022_03_04_14_04_44\n",
      "Set stats: \n",
      "  --number of fragments: 52\n",
      "  --total adjacent pairs: 202; total not adjacent pairs: 1124\n",
      "  --dataset for set will contain: 404 pairs\n",
      "     --> adj: 202    n-adj: 202\n",
      "Set completed in: 2.672 seconds: added 404 pairs --> adj: 202   n_adj: 202\n",
      "currently dataset contains 92426 pairs. \n",
      "\n",
      "\n",
      "Starting set 56: folder - generatedTest_2022_03_04_14_05_05\n",
      "Set stats: \n",
      "  --number of fragments: 63\n",
      "  --total adjacent pairs: 272; total not adjacent pairs: 1681\n",
      "  --dataset for set will contain: 544 pairs\n",
      "     --> adj: 272    n-adj: 272\n",
      "Set completed in: 3.093 seconds: added 544 pairs --> adj: 272   n_adj: 272\n",
      "currently dataset contains 92970 pairs. \n",
      "\n",
      "\n",
      "Starting set 57: folder - generatedTest_2022_03_04_14_06_12\n",
      "Set stats: \n",
      "  --number of fragments: 216\n",
      "  --total adjacent pairs: 1093; total not adjacent pairs: 22127\n",
      "  --dataset for set will contain: 2186 pairs\n",
      "     --> adj: 1093    n-adj: 1093\n",
      "Set completed in: 11.059 seconds: added 2186 pairs --> adj: 1093   n_adj: 1093\n",
      "currently dataset contains 95156 pairs. \n",
      "\n",
      "\n",
      "Starting set 58: folder - generatedTest_2022_03_04_14_07_17\n",
      "Set stats: \n",
      "  --number of fragments: 187\n",
      "  --total adjacent pairs: 892; total not adjacent pairs: 16499\n",
      "  --dataset for set will contain: 1784 pairs\n",
      "     --> adj: 892    n-adj: 892\n",
      "Set completed in: 9.059 seconds: added 1784 pairs --> adj: 892   n_adj: 892\n",
      "currently dataset contains 96940 pairs. \n",
      "\n",
      "\n",
      "Starting set 59: folder - generatedTest_2022_03_04_14_08_09\n",
      "Set stats: \n",
      "  --number of fragments: 203\n",
      "  --total adjacent pairs: 996; total not adjacent pairs: 19507\n",
      "  --dataset for set will contain: 1992 pairs\n",
      "     --> adj: 996    n-adj: 996\n",
      "Set completed in: 10.711 seconds: added 1992 pairs --> adj: 996   n_adj: 996\n",
      "currently dataset contains 98932 pairs. \n",
      "\n",
      "\n",
      "Starting set 60: folder - generatedTest_2022_03_04_14_08_52\n",
      "Set stats: \n",
      "  --number of fragments: 120\n",
      "  --total adjacent pairs: 563; total not adjacent pairs: 6577\n",
      "  --dataset for set will contain: 1126 pairs\n",
      "     --> adj: 563    n-adj: 563\n",
      "Set completed in: 5.886 seconds: added 1126 pairs --> adj: 563   n_adj: 563\n",
      "currently dataset contains 100058 pairs. \n",
      "\n",
      "\n",
      "Starting set 61: folder - generatedTest_2022_03_04_14_09_22\n",
      "Set stats: \n",
      "  --number of fragments: 111\n",
      "  --total adjacent pairs: 510; total not adjacent pairs: 5595\n",
      "  --dataset for set will contain: 1020 pairs\n",
      "     --> adj: 510    n-adj: 510\n",
      "Set completed in: 6.052 seconds: added 1020 pairs --> adj: 510   n_adj: 510\n",
      "currently dataset contains 101078 pairs. \n",
      "\n",
      "\n",
      "Starting set 62: folder - generatedTest_2022_03_04_14_09_52\n",
      "Set stats: \n",
      "  --number of fragments: 104\n",
      "  --total adjacent pairs: 447; total not adjacent pairs: 4909\n",
      "  --dataset for set will contain: 894 pairs\n",
      "     --> adj: 447    n-adj: 447\n",
      "Set completed in: 5.389 seconds: added 894 pairs --> adj: 447   n_adj: 447\n",
      "currently dataset contains 101972 pairs. \n",
      "\n",
      "\n",
      "Starting set 63: folder - generatedTest_2022_03_04_14_11_24\n",
      "Set stats: \n",
      "  --number of fragments: 192\n",
      "  --total adjacent pairs: 938; total not adjacent pairs: 17398\n",
      "  --dataset for set will contain: 1876 pairs\n",
      "     --> adj: 938    n-adj: 938\n",
      "Set completed in: 10.455 seconds: added 1876 pairs --> adj: 938   n_adj: 938\n",
      "currently dataset contains 103848 pairs. \n",
      "\n",
      "\n",
      "Starting set 64: folder - generatedTest_2022_03_04_14_12_11\n",
      "Set stats: \n",
      "  --number of fragments: 190\n",
      "  --total adjacent pairs: 897; total not adjacent pairs: 17058\n",
      "  --dataset for set will contain: 1794 pairs\n",
      "     --> adj: 897    n-adj: 897\n",
      "Set completed in: 9.630 seconds: added 1794 pairs --> adj: 897   n_adj: 897\n",
      "currently dataset contains 105642 pairs. \n",
      "\n",
      "\n",
      "Starting set 65: folder - generatedTest_2022_03_04_14_13_16\n",
      "Set stats: \n",
      "  --number of fragments: 188\n",
      "  --total adjacent pairs: 901; total not adjacent pairs: 16677\n",
      "  --dataset for set will contain: 1802 pairs\n",
      "     --> adj: 901    n-adj: 901\n",
      "Set completed in: 9.902 seconds: added 1802 pairs --> adj: 901   n_adj: 901\n",
      "currently dataset contains 107444 pairs. \n",
      "\n",
      "\n",
      "Starting set 66: folder - generatedTest_2022_03_04_14_14_20\n",
      "Set stats: \n",
      "  --number of fragments: 160\n",
      "  --total adjacent pairs: 760; total not adjacent pairs: 11960\n",
      "  --dataset for set will contain: 1520 pairs\n",
      "     --> adj: 760    n-adj: 760\n",
      "Set completed in: 8.218 seconds: added 1520 pairs --> adj: 760   n_adj: 760\n",
      "currently dataset contains 108964 pairs. \n",
      "\n",
      "\n",
      "Starting set 67: folder - generatedTest_2022_03_04_14_14_56\n",
      "Set stats: \n",
      "  --number of fragments: 137\n",
      "  --total adjacent pairs: 598; total not adjacent pairs: 8718\n",
      "  --dataset for set will contain: 1196 pairs\n",
      "     --> adj: 598    n-adj: 598\n",
      "Set completed in: 7.519 seconds: added 1196 pairs --> adj: 598   n_adj: 598\n",
      "currently dataset contains 110160 pairs. \n",
      "\n",
      "\n",
      "Starting set 68: folder - generatedTest_2022_03_04_14_15_36\n",
      "Set stats: \n",
      "  --number of fragments: 132\n",
      "  --total adjacent pairs: 578; total not adjacent pairs: 8068\n",
      "  --dataset for set will contain: 1156 pairs\n",
      "     --> adj: 578    n-adj: 578\n",
      "Set completed in: 7.217 seconds: added 1156 pairs --> adj: 578   n_adj: 578\n",
      "currently dataset contains 111316 pairs. \n",
      "\n",
      "\n",
      "Starting set 69: folder - generatedTest_2022_03_04_14_17_27\n",
      "Set stats: \n",
      "  --number of fragments: 216\n",
      "  --total adjacent pairs: 1068; total not adjacent pairs: 22152\n",
      "  --dataset for set will contain: 2136 pairs\n",
      "     --> adj: 1068    n-adj: 1068\n",
      "Set completed in: 11.966 seconds: added 2136 pairs --> adj: 1068   n_adj: 1068\n",
      "currently dataset contains 113452 pairs. \n",
      "\n",
      "\n",
      "Starting set 70: folder - generatedTest_2022_03_04_14_18_32\n",
      "Set stats: \n",
      "  --number of fragments: 204\n",
      "  --total adjacent pairs: 999; total not adjacent pairs: 19707\n",
      "  --dataset for set will contain: 1998 pairs\n",
      "     --> adj: 999    n-adj: 999\n",
      "Set completed in: 11.049 seconds: added 1998 pairs --> adj: 999   n_adj: 999\n",
      "currently dataset contains 115450 pairs. \n",
      "\n",
      "\n",
      "Starting set 71: folder - generatedTest_2022_03_04_14_20_42\n",
      "Set stats: \n",
      "  --number of fragments: 194\n",
      "  --total adjacent pairs: 906; total not adjacent pairs: 17815\n",
      "  --dataset for set will contain: 1812 pairs\n",
      "     --> adj: 906    n-adj: 906\n",
      "Set completed in: 10.395 seconds: added 1812 pairs --> adj: 906   n_adj: 906\n",
      "currently dataset contains 117262 pairs. \n",
      "\n",
      "\n",
      "Starting set 72: folder - generatedTest_2022_03_04_14_22_05\n",
      "Set stats: \n",
      "  --number of fragments: 84\n",
      "  --total adjacent pairs: 368; total not adjacent pairs: 3118\n",
      "  --dataset for set will contain: 736 pairs\n",
      "     --> adj: 368    n-adj: 368\n",
      "Set completed in: 3.951 seconds: added 736 pairs --> adj: 368   n_adj: 368\n",
      "currently dataset contains 117998 pairs. \n",
      "\n",
      "\n",
      "Starting set 73: folder - generatedTest_2022_03_04_14_23_09\n",
      "Set stats: \n",
      "  --number of fragments: 82\n",
      "  --total adjacent pairs: 359; total not adjacent pairs: 2962\n",
      "  --dataset for set will contain: 718 pairs\n",
      "     --> adj: 359    n-adj: 359\n",
      "Set completed in: 4.611 seconds: added 718 pairs --> adj: 359   n_adj: 359\n",
      "currently dataset contains 118716 pairs. \n",
      "\n",
      "\n",
      "Starting set 74: folder - generatedTest_2022_03_04_14_24_01\n",
      "Set stats: \n",
      "  --number of fragments: 80\n",
      "  --total adjacent pairs: 332; total not adjacent pairs: 2828\n",
      "  --dataset for set will contain: 664 pairs\n",
      "     --> adj: 332    n-adj: 332\n",
      "Set completed in: 3.793 seconds: added 664 pairs --> adj: 332   n_adj: 332\n",
      "currently dataset contains 119380 pairs. \n",
      "\n",
      "\n",
      "Starting set 75: folder - generatedTest_2022_03_04_14_25_05\n",
      "Set stats: \n",
      "  --number of fragments: 105\n",
      "  --total adjacent pairs: 474; total not adjacent pairs: 4986\n",
      "  --dataset for set will contain: 948 pairs\n",
      "     --> adj: 474    n-adj: 474\n",
      "Set completed in: 5.514 seconds: added 948 pairs --> adj: 474   n_adj: 474\n",
      "currently dataset contains 120328 pairs. \n",
      "\n",
      "\n",
      "Starting set 76: folder - generatedTest_2022_03_04_14_25_32\n",
      "Set stats: \n",
      "  --number of fragments: 94\n",
      "  --total adjacent pairs: 390; total not adjacent pairs: 3981\n",
      "  --dataset for set will contain: 780 pairs\n",
      "     --> adj: 390    n-adj: 390\n",
      "Set completed in: 4.552 seconds: added 780 pairs --> adj: 390   n_adj: 390\n",
      "currently dataset contains 121108 pairs. \n",
      "\n",
      "\n",
      "Starting set 77: folder - generatedTest_2022_03_04_14_25_59\n",
      "Set stats: \n",
      "  --number of fragments: 84\n",
      "  --total adjacent pairs: 358; total not adjacent pairs: 3128\n",
      "  --dataset for set will contain: 716 pairs\n",
      "     --> adj: 358    n-adj: 358\n",
      "Set completed in: 4.192 seconds: added 716 pairs --> adj: 358   n_adj: 358\n",
      "currently dataset contains 121824 pairs. \n",
      "\n",
      "\n",
      "Starting set 78: folder - generatedTest_2022_03_04_14_30_35\n",
      "Set stats: \n",
      "  --number of fragments: 729\n",
      "  --total adjacent pairs: 3905; total not adjacent pairs: 261451\n",
      "  --dataset for set will contain: 7810 pairs\n",
      "     --> adj: 3905    n-adj: 3905\n",
      "Set completed in: 38.684 seconds: added 7810 pairs --> adj: 3905   n_adj: 3905\n",
      "currently dataset contains 129634 pairs. \n",
      "\n",
      "\n",
      "Starting set 79: folder - generatedTest_2022_03_04_14_34_51\n",
      "Set stats: \n",
      "  --number of fragments: 691\n",
      "  --total adjacent pairs: 3644; total not adjacent pairs: 234751\n",
      "  --dataset for set will contain: 7288 pairs\n",
      "     --> adj: 3644    n-adj: 3644\n",
      "Set completed in: 42.064 seconds: added 7288 pairs --> adj: 3644   n_adj: 3644\n",
      "currently dataset contains 136922 pairs. \n",
      "\n",
      "\n",
      "Starting set 80: folder - generatedTest_2022_03_04_14_39_35\n",
      "Set stats: \n",
      "  --number of fragments: 620\n",
      "  --total adjacent pairs: 3247; total not adjacent pairs: 188643\n",
      "  --dataset for set will contain: 6494 pairs\n",
      "     --> adj: 3247    n-adj: 3247\n",
      "Set completed in: 34.663 seconds: added 6494 pairs --> adj: 3247   n_adj: 3247\n",
      "currently dataset contains 143416 pairs. \n",
      "\n",
      "\n",
      "Starting set 81: folder - generatedTest_2022_03_04_14_42_00\n",
      "Set stats: \n",
      "  --number of fragments: 343\n",
      "  --total adjacent pairs: 1788; total not adjacent pairs: 56865\n",
      "  --dataset for set will contain: 3576 pairs\n",
      "     --> adj: 1788    n-adj: 1788\n",
      "Set completed in: 18.569 seconds: added 3576 pairs --> adj: 1788   n_adj: 1788\n",
      "currently dataset contains 146992 pairs. \n",
      "\n",
      "\n",
      "Starting set 82: folder - generatedTest_2022_03_04_14_43_20\n",
      "Set stats: \n",
      "  --number of fragments: 276\n",
      "  --total adjacent pairs: 1342; total not adjacent pairs: 36608\n",
      "  --dataset for set will contain: 2684 pairs\n",
      "     --> adj: 1342    n-adj: 1342\n",
      "Set completed in: 14.470 seconds: added 2684 pairs --> adj: 1342   n_adj: 1342\n",
      "currently dataset contains 149676 pairs. \n",
      "\n",
      "\n",
      "Starting set 83: folder - generatedTest_2022_03_04_14_44_51\n",
      "Set stats: \n",
      "  --number of fragments: 287\n",
      "  --total adjacent pairs: 1450; total not adjacent pairs: 39591\n",
      "  --dataset for set will contain: 2900 pairs\n",
      "     --> adj: 1450    n-adj: 1450\n",
      "Set completed in: 16.552 seconds: added 2900 pairs --> adj: 1450   n_adj: 1450\n",
      "currently dataset contains 152576 pairs. \n",
      "\n",
      "\n",
      "Starting set 84: folder - generatedTest_2022_03_04_14_45_43\n",
      "Set stats: \n",
      "  --number of fragments: 140\n",
      "  --total adjacent pairs: 664; total not adjacent pairs: 9066\n",
      "  --dataset for set will contain: 1328 pairs\n",
      "     --> adj: 664    n-adj: 664\n",
      "Set completed in: 9.234 seconds: added 1328 pairs --> adj: 664   n_adj: 664\n",
      "currently dataset contains 153904 pairs. \n",
      "\n",
      "\n",
      "Starting set 85: folder - generatedTest_2022_03_04_14_46_17\n",
      "Set stats: \n",
      "  --number of fragments: 124\n",
      "  --total adjacent pairs: 537; total not adjacent pairs: 7089\n",
      "  --dataset for set will contain: 1074 pairs\n",
      "     --> adj: 537    n-adj: 537\n",
      "Set completed in: 7.014 seconds: added 1074 pairs --> adj: 537   n_adj: 537\n",
      "currently dataset contains 154978 pairs. \n",
      "\n",
      "\n",
      "Starting set 86: folder - generatedTest_2022_03_04_14_46_56\n",
      "Set stats: \n",
      "  --number of fragments: 115\n",
      "  --total adjacent pairs: 527; total not adjacent pairs: 6028\n",
      "  --dataset for set will contain: 1054 pairs\n",
      "     --> adj: 527    n-adj: 527\n",
      "Set completed in: 6.474 seconds: added 1054 pairs --> adj: 527   n_adj: 527\n",
      "currently dataset contains 156032 pairs. \n",
      "\n",
      "\n",
      "Starting set 87: folder - generatedTest_2022_03_04_14_48_22\n",
      "Set stats: \n",
      "  --number of fragments: 175\n",
      "  --total adjacent pairs: 857; total not adjacent pairs: 14368\n",
      "  --dataset for set will contain: 1714 pairs\n",
      "     --> adj: 857    n-adj: 857\n",
      "Set completed in: 10.902 seconds: added 1714 pairs --> adj: 857   n_adj: 857\n",
      "currently dataset contains 157746 pairs. \n",
      "\n",
      "\n",
      "Starting set 88: folder - generatedTest_2022_03_04_14_49_05\n",
      "Set stats: \n",
      "  --number of fragments: 153\n",
      "  --total adjacent pairs: 702; total not adjacent pairs: 10926\n",
      "  --dataset for set will contain: 1404 pairs\n",
      "     --> adj: 702    n-adj: 702\n",
      "Set completed in: 9.685 seconds: added 1404 pairs --> adj: 702   n_adj: 702\n",
      "currently dataset contains 159150 pairs. \n",
      "\n",
      "\n",
      "Starting set 89: folder - generatedTest_2022_03_04_14_49_49\n",
      "Set stats: \n",
      "  --number of fragments: 156\n",
      "  --total adjacent pairs: 723; total not adjacent pairs: 11367\n",
      "  --dataset for set will contain: 1446 pairs\n",
      "     --> adj: 723    n-adj: 723\n",
      "Set completed in: 8.099 seconds: added 1446 pairs --> adj: 723   n_adj: 723\n",
      "currently dataset contains 160596 pairs. \n",
      "\n",
      "\n",
      "Starting set 90: folder - generatedTest_2022_03_04_14_52_51\n",
      "Set stats: \n",
      "  --number of fragments: 504\n",
      "  --total adjacent pairs: 2707; total not adjacent pairs: 124049\n",
      "  --dataset for set will contain: 5414 pairs\n",
      "     --> adj: 2707    n-adj: 2707\n",
      "Set completed in: 26.830 seconds: added 5414 pairs --> adj: 2707   n_adj: 2707\n",
      "currently dataset contains 166010 pairs. \n",
      "\n",
      "\n",
      "Starting set 91: folder - generatedTest_2022_03_04_14_55_34\n",
      "Set stats: \n",
      "  --number of fragments: 415\n",
      "  --total adjacent pairs: 2137; total not adjacent pairs: 83768\n",
      "  --dataset for set will contain: 4274 pairs\n",
      "     --> adj: 2137    n-adj: 2137\n",
      "Set completed in: 21.021 seconds: added 4274 pairs --> adj: 2137   n_adj: 2137\n",
      "currently dataset contains 170284 pairs. \n",
      "\n",
      "\n",
      "Starting set 92: folder - generatedTest_2022_03_04_14_58_08\n",
      "Set stats: \n",
      "  --number of fragments: 461\n",
      "  --total adjacent pairs: 2369; total not adjacent pairs: 103661\n",
      "  --dataset for set will contain: 4738 pairs\n",
      "     --> adj: 2369    n-adj: 2369\n",
      "Set completed in: 24.706 seconds: added 4738 pairs --> adj: 2369   n_adj: 2369\n",
      "currently dataset contains 175022 pairs. \n",
      "\n",
      "\n",
      "Starting set 93: folder - generatedTest_2022_03_04_14_59_11\n",
      "Set stats: \n",
      "  --number of fragments: 168\n",
      "  --total adjacent pairs: 800; total not adjacent pairs: 13228\n",
      "  --dataset for set will contain: 1600 pairs\n",
      "     --> adj: 800    n-adj: 800\n",
      "Set completed in: 8.653 seconds: added 1600 pairs --> adj: 800   n_adj: 800\n",
      "currently dataset contains 176622 pairs. \n",
      "\n",
      "\n",
      "Starting set 94: folder - generatedTest_2022_03_04_15_02_42\n",
      "Set stats: \n",
      "  --number of fragments: 161\n",
      "  --total adjacent pairs: 751; total not adjacent pairs: 12129\n",
      "  --dataset for set will contain: 1502 pairs\n",
      "     --> adj: 751    n-adj: 751\n",
      "Set completed in: 7.808 seconds: added 1502 pairs --> adj: 751   n_adj: 751\n",
      "currently dataset contains 178124 pairs. \n",
      "\n",
      "\n",
      "Starting set 95: folder - generatedTest_2022_03_04_15_03_51\n",
      "Set stats: \n",
      "  --number of fragments: 160\n",
      "  --total adjacent pairs: 742; total not adjacent pairs: 11978\n",
      "  --dataset for set will contain: 1484 pairs\n",
      "     --> adj: 742    n-adj: 742\n",
      "Set completed in: 7.487 seconds: added 1484 pairs --> adj: 742   n_adj: 742\n",
      "currently dataset contains 179608 pairs. \n",
      "Dataset contains 18255 fragments --> 3079291 total pairs \n",
      "we consider only:  179608  pairs, of which  89831 are adjacent\n",
      "Train set: 125719,   test set: 26787, val set: 26942\n",
      "but it should be: train,test,val: 125725,26941,26941\n",
      "total time: 1101.942 seconds\n"
     ]
    }
   ],
   "source": [
    "create_dataset(main_path,num_points,alpha=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6305d24f3e56ac2ca2871aacb4eb187216de08a2a8667a1a48c2c574de0d34f3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('EAI': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
